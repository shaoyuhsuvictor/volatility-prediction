{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817587ff",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8af3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import scipy.stats as stats\n",
    "\n",
    "from utils import data_prep as dp, feature_gen as fg, feature_select as fs, backtest as bt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b61a20b",
   "metadata": {},
   "source": [
    "### 2. Load & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7250fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange = \"binance\"\n",
    "\n",
    "start_date = \"20230101\"\n",
    "end_date = \"20241231\"\n",
    "\n",
    "start_dt = dt.datetime.strptime(start_date, \"%Y%m%d\")\n",
    "end_dt = dt.datetime.strptime(end_date, \"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/data/time_series/market_data/\"\n",
    "\n",
    "level1_data = dp.get_files(start_dt, end_dt, \"level1\", exchange, \"futures\", \"BTCUSDT\",DATA_PATH)\n",
    "book_data = dp.get_files(start_dt, end_dt, \"book\", exchange, \"futures\", \"BTCUSDT\",DATA_PATH)\n",
    "trade_data = dp.get_files(start_dt, end_dt, \"trade\", exchange, \"futures\", \"BTCUSDT\",DATA_PATH)\n",
    "\n",
    "level1_data.shape, book_data.shape, trade_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edfbbad",
   "metadata": {},
   "source": [
    "### 2.1 Carryover Analysis & Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze carryover data quality\n",
    "carryover_stats = dp.analyze_carryover(\n",
    "    level1_data, book_data, trade_data,\n",
    "    names=[\"level1_data\", \"book_data\", \"trade_data\"]\n",
    ")\n",
    "\n",
    "for name, status in carryover_stats.items():\n",
    "    if \"status\" in status:\n",
    "        print(f\"\\n{name}: {status['status']}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Total rows: {status['total_rows']:,}\")\n",
    "    print(f\"  Missing original data (carryover != 0): {status['missing_original']:,} ({status['missing_original_pct']:.2f}%)\")\n",
    "    print(f\"  Completely missing (carryover == -1): {status['completely_missing']:,} ({status['completely_missing_pct']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749eade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "level1_data, book_data, trade_data = dp.clean_carryover(\n",
    "    level1_data, book_data, trade_data,\n",
    "    carryover_weight=0.5,\n",
    "    remove_completely_missing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1072b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps to datetime\n",
    "level1_data['ts_end'] = pd.to_datetime(level1_data['ts_end'], unit='ms')\n",
    "book_data[['ts_end', 'ts_book']] = book_data[['ts_end', 'ts_book']].apply(pd.to_datetime, unit='ms')\n",
    "trade_data['ts_end'] = pd.to_datetime(trade_data['ts_end'], unit='ms')\n",
    "\n",
    "# Set index to ts_end\n",
    "level1_data.set_index('ts_end', inplace=True)\n",
    "book_data.set_index('ts_end', inplace=True)\n",
    "trade_data.set_index('ts_end', inplace=True)\n",
    "\n",
    "# Align time series data\n",
    "(level1_data, book_data, trade_data), start, end = dp.align_ts(level1_data, book_data, trade_data)\n",
    "\n",
    "# Create a common time index\n",
    "time_idx = pd.date_range(start=start, end=end, freq='1min')\n",
    "\n",
    "time_idx[[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83002cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log return\n",
    "level1_data['log_return'] = np.log(level1_data['close_mid'] / level1_data['close_mid'].shift(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07200fd",
   "metadata": {},
   "source": [
    "### 3. Build Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = [1, 5, 15, 30, 60, 120]\n",
    "features_df = fg.build_features(level1_data, book_data, trade_data, taus)\n",
    "features_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff35b7d",
   "metadata": {},
   "source": [
    "### 4. Build Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66028a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = fg.target_rv(level1_data, horizons=[60])\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81103874",
   "metadata": {},
   "source": [
    "### 5. Combine Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([features_df, target_df], axis=1)\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "# Add data quality columns from level1_data\n",
    "df[\"is_carryover\"] = level1_data[\"is_carryover\"]\n",
    "df[\"sample_weight\"] = level1_data[\"sample_weight\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e31c9cb",
   "metadata": {},
   "source": [
    "### 6. Walk-Forward CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1590bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [\n",
    "    (\"2023-01-01\", \"2023-09-30\", \"2023-10-01\", \"2023-12-31\"), # fold 1\n",
    "    (\"2023-04-01\", \"2023-12-31\", \"2024-01-01\", \"2024-03-31\"), # fold 2\n",
    "    (\"2023-07-01\", \"2024-03-31\", \"2024-04-01\", \"2024-06-30\"), # fold 3\n",
    "]\n",
    "\n",
    "target = target_df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46611a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_leaves_list = [31, 63, 127]\n",
    "learning_rates  = [0.05, 0.10]\n",
    "\n",
    "param_grid = [\n",
    "    {\"num_leaves\": nl, \"learning_rate\": lr, \"n_estimators\": 300}\n",
    "    for nl in num_leaves_list\n",
    "    for lr in learning_rates\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb(train_df, val_df, feats, target, params, use_sample_weight=True):\n",
    "    model = lgb.LGBMRegressor(\n",
    "        num_leaves=params[\"num_leaves\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        verbose=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    if use_sample_weight and \"sample_weight\" in train_df.columns:\n",
    "        sample_weights = train_df[\"sample_weight\"].values\n",
    "        model.fit(train_df[feats], train_df[target], sample_weight=sample_weights)\n",
    "    else:\n",
    "        model.fit(train_df[feats], train_df[target])\n",
    "    pred = model.predict(val_df[feats])\n",
    "\n",
    "    rmse = mean_squared_error(val_df[target], pred) ** 0.5\n",
    "    mae  = mean_absolute_error(val_df[target], pred)\n",
    "    ic   = stats.spearmanr(pred, val_df[target]).correlation\n",
    "\n",
    "    return rmse, mae, ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd029e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_start, tr_end, va_start, va_end = folds[0]\n",
    "test_params = param_grid[0]  # Use first hyperparameter set\n",
    "\n",
    "train_df = df[(df.index >= tr_start) & (df.index <= tr_end)]\n",
    "val_df   = df[(df.index >= va_start) & (df.index <= va_end)]\n",
    "\n",
    "print(f\"\\nFold 1: Train {tr_start}→{tr_end}, Val {va_start}→{va_end}\")\n",
    "print(f\"Train set: {len(train_df)} rows\")\n",
    "print(f\"  - Original data (weight=1.0): {(~train_df['is_carryover']).sum()}\")\n",
    "print(f\"  - Carryover data (weight=0.5): {train_df['is_carryover'].sum()}\")\n",
    "\n",
    "# Feature selection\n",
    "feats_ic, ic_series = fs.select_ic(train_df, target)\n",
    "feats, _, _ = fs.prune_corr(train_df, feats_ic, ic_series)\n",
    "\n",
    "# Train WITHOUT sample weighting (original method)\n",
    "print(\"METHOD 1: WITHOUT Sample Weighting (Original)\")\n",
    "rmse_no_weight, mae_no_weight, ic_no_weight = train_lgb(\n",
    "    train_df, val_df, feats, target, test_params, use_sample_weight=False\n",
    ")\n",
    "print(f\"Results: RMSE={rmse_no_weight:.6f}, MAE={mae_no_weight:.6f}, IC={ic_no_weight:.6f}\")\n",
    "\n",
    "print(\"METHOD 2: WITH Sample Weighting (Improved)\")\n",
    "rmse_with_weight, mae_with_weight, ic_with_weight = train_lgb(\n",
    "    train_df, val_df, feats, target, test_params, use_sample_weight=True\n",
    ")\n",
    "print(f\"Results: RMSE={rmse_with_weight:.6f}, MAE={mae_with_weight:.6f}, IC={ic_with_weight:.6f}\")\n",
    "\n",
    "# Show differences\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"IMPACT OF SAMPLE WEIGHTING\")\n",
    "print(\"=\" * 80)\n",
    "rmse_diff = rmse_with_weight - rmse_no_weight\n",
    "mae_diff = mae_with_weight - mae_no_weight\n",
    "ic_diff = ic_with_weight - ic_no_weight\n",
    "\n",
    "print(f\"RMSE change: {rmse_diff:+.6f} ({100*rmse_diff/rmse_no_weight:+.2f}%)\")\n",
    "print(f\"MAE change:  {mae_diff:+.6f} ({100*mae_diff/mae_no_weight:+.2f}%)\")\n",
    "print(f\"IC change:   {ic_diff:+.6f} ({100*ic_diff/ic_no_weight:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fcaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = []\n",
    "\n",
    "for p_i, params in enumerate(param_grid, 1):\n",
    "    print(f\"\\nHyperparameter set {p_i}/{len(param_grid)}: {params}\")\n",
    "    fold_scores = []\n",
    "\n",
    "    for f_i, (tr_start, tr_end, va_start, va_end) in enumerate(folds, 1):\n",
    "        print(f\"\\nFold {f_i}\")\n",
    "        print(f\"  Training window:   {tr_start} to {tr_end}\")\n",
    "        print(f\"  Validation window: {va_start} to {va_end}\")\n",
    "\n",
    "        train_df = df[(df.index >= tr_start) & (df.index <= tr_end)]\n",
    "        val_df   = df[(df.index >= va_start) & (df.index <= va_end)]\n",
    "\n",
    "        print(\"  Selecting features (IC ranking)...\")\n",
    "        feats_ic, ic_series = fs.select_ic(train_df, target)\n",
    "\n",
    "        print(\"  Pruning correlated features...\")\n",
    "        feats, _, _ = fs.prune_corr(train_df, feats_ic, ic_series)\n",
    "\n",
    "        print(f\"  Features used: {len(feats)}\")\n",
    "\n",
    "        print(\"  Training model...\")\n",
    "        rmse, mae, ic = train_lgb(train_df, val_df, feats, target, params, use_sample_weight=True)\n",
    "\n",
    "        print(f\"  Fold {f_i} RMSE={rmse:.4f}, MAE={mae:.4f}, IC={ic:.4f}\")\n",
    "\n",
    "        fold_scores.append({\"rmse\": rmse, \"mae\": mae, \"ic\": ic})\n",
    "\n",
    "    avg_rmse = np.mean([s[\"rmse\"] for s in fold_scores])\n",
    "    avg_mae  = np.mean([s[\"mae\"]  for s in fold_scores])\n",
    "    avg_ic   = np.mean([s[\"ic\"]   for s in fold_scores])\n",
    "\n",
    "    tuning_results.append({\n",
    "        \"params\": params,\n",
    "        \"avg_rmse\": avg_rmse,\n",
    "        \"avg_mae\": avg_mae,\n",
    "        \"avg_ic\": avg_ic\n",
    "    })\n",
    "\n",
    "    print(f\"\\nFinished hyperparameter set {p_i}\")\n",
    "    print(f\"  Average RMSE={avg_rmse:.4f}, MAE={avg_mae:.4f}, IC={avg_ic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f03dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results_sorted = sorted(tuning_results, key=lambda x: -x[\"avg_ic\"])\n",
    "best_params = tuning_results_sorted[0][\"params\"]\n",
    "\n",
    "print(\"\\nBest hyperparameters based on IC:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791f8b3",
   "metadata": {},
   "source": [
    "### 8. Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2803f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretest_df = df[: \"2024-06-30\"]\n",
    "test_df    = df[\"2024-07-01\":]\n",
    "\n",
    "# Feature selection on ALL pre-test data\n",
    "feats_ic, ic_series = fs.select_ic(pretest_df, target)\n",
    "feats, _, _ = fs.prune_corr(pretest_df, feats_ic, ic_series)\n",
    "\n",
    "# Final model training (with sample weighting for carryover data quality)\n",
    "final_model = lgb.LGBMRegressor(\n",
    "    num_leaves=best_params[\"num_leaves\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    verbose=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Use sample weights: carryover data gets 0.5 weight, original data gets 1.0\n",
    "sample_weights = pretest_df[\"sample_weight\"].values\n",
    "final_model.fit(pretest_df[feats], pretest_df[target], sample_weight=sample_weights)\n",
    "oos_pred = final_model.predict(test_df[feats])\n",
    "\n",
    "rmse = mean_squared_error(test_df[target], oos_pred)**0.5\n",
    "mae  = mean_absolute_error(test_df[target], oos_pred)\n",
    "ic   = stats.spearmanr(oos_pred, test_df[target]).correlation\n",
    "\n",
    "print(\"\\nFinal OOS Performance\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"IC  : {ic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9254707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Spearman correlation (feature vs target)\n",
    "spearman_corr = pretest_df[feats + [target]].corr(method=\"spearman\")[target].drop(target)\n",
    "\n",
    "plt.figure(figsize=(6, max(6, len(feats)*0.3)))\n",
    "sns.heatmap(\n",
    "    spearman_corr.to_frame(),\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    fmt=\".2f\",\n",
    "    cbar=False\n",
    ")\n",
    "plt.title(\"Spearman Correlation (Selected Features vs Target)\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr = pretest_df[feats].corr(method=\"pearson\")\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    pearson_corr,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    square=True,\n",
    "    linewidths=0.5\n",
    ")\n",
    "plt.title(\"Pearson Correlation Heatmap (Selected Features)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(test_df.index, oos_pred, label='Predicted Volatility', color='blue', alpha=0.5)\n",
    "plt.plot(test_df.index, test_df[target], label='Actual Realized Volatility', color='orange', alpha=0.5)\n",
    "plt.title('Predicted vs Actual Realized Volatility (Test Period)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Volatility')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0737e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(test_df[target], bins=150, alpha=0.6, label='Actual Volatility', color='orange',density=True)\n",
    "plt.hist(oos_pred, bins=150, alpha=0.6, label='Predicted Volatility', color='blue',density=True)\n",
    "plt.title('Distribution of Actual vs Predicted Volatility (Test Period)')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(test_df[target], bins=150, alpha=0.6, label='Actual Volatility',\n",
    "         color='orange', density=True)\n",
    "plt.hist(oos_pred, bins=150, alpha=0.6, label='Predicted Volatility',\n",
    "         color='blue', density=True)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.title('Log-Scaled Distribution of Actual vs Predicted Volatility (Test Period)')\n",
    "plt.xlabel('Volatility (log scale)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cf0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Scatter plot: Predicted vs Actual Volatility\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(oos_pred, test_df[target], alpha=0.3, color='blue')\n",
    "plt.xlabel('Predicted Volatility')\n",
    "plt.ylabel('Actual Realized Volatility')\n",
    "plt.title('Predicted vs Actual Volatility (Test Period)')\n",
    "\n",
    "# Calculate Spearman correlation\n",
    "spearman_corr, _ = spearmanr(oos_pred, test_df[target])\n",
    "plt.annotate(f'Spearman ρ = {spearman_corr:.4f}', xy=(0.05, 0.95), xycoords='axes fraction', fontsize=14, color='darkred', ha='left', va='top', bbox=dict(boxstyle='round,pad=0.3', fc='white', ec='darkred', lw=2))\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ead1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling 30-day Spearman IC\n",
    "\n",
    "pred_series = pd.Series(oos_pred, index=test_df.index)\n",
    "actual_series = test_df[target]\n",
    "\n",
    "# Calculate rolling Spearman correlation (30 days)\n",
    "rolling_window = 30 * 24 * 60  # 30 days in minute data)\n",
    "rolling_ic = []\n",
    "rolling_dates = []\n",
    "\n",
    "for i in range(len(test_df) - rolling_window):\n",
    "    window_pred = pred_series.iloc[i:i+rolling_window]\n",
    "    window_actual = actual_series.iloc[i:i+rolling_window]\n",
    "    corr, _ = spearmanr(window_pred, window_actual)\n",
    "    rolling_ic.append(corr)\n",
    "    rolling_dates.append(test_df.index[i+rolling_window])\n",
    "\n",
    "rolling_ic = np.array(rolling_ic)\n",
    "rolling_dates = pd.DatetimeIndex(rolling_dates)\n",
    "\n",
    "# Plot rolling Spearman IC\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(rolling_dates, rolling_ic, linewidth=2, color='blue', alpha=0.7)\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "plt.axhline(y=np.nanmean(rolling_ic), color='red', linestyle='--', linewidth=2, label=f'Mean IC: {np.nanmean(rolling_ic):.4f}')\n",
    "plt.fill_between(rolling_dates, rolling_ic, 0, where=(rolling_ic > 0), alpha=0.2, color='green', label='Positive IC')\n",
    "plt.fill_between(rolling_dates, rolling_ic, 0, where=(rolling_ic <= 0), alpha=0.2, color='red', label='Negative IC')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Spearman Correlation')\n",
    "plt.title('Rolling 30-Day Spearman IC (Predicted vs Actual Volatility)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f'Rolling 30-Day Spearman IC Statistics:')\n",
    "print(f'  Mean: {np.nanmean(rolling_ic):.4f}')\n",
    "print(f'  Median: {np.nanmedian(rolling_ic):.4f}')\n",
    "print(f'  Std: {np.nanstd(rolling_ic):.4f}')\n",
    "print(f'  Min: {np.nanmin(rolling_ic):.4f}')\n",
    "print(f'  Max: {np.nanmax(rolling_ic):.4f}')\n",
    "print(f'  Positive IC periods: {(rolling_ic > 0).sum()}/{len(rolling_ic)} ({100*(rolling_ic > 0).sum()/len(rolling_ic):.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d99817",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(final_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e95ac",
   "metadata": {},
   "source": [
    "### Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d119bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretest_rv = df.loc[\"2023-01-01\":\"2024-06-30\", \"target_rv_fwd60m\"]\n",
    "\n",
    "sigma_target = np.median(pretest_rv)\n",
    "print(f\"Median of pre-test realized vol: {sigma_target:.4f}\\n\")\n",
    "\n",
    "oos_pred = pd.Series(oos_pred, index=test_df.index)\n",
    "\n",
    "actual_returns = df[\"log_ret_1m\"].loc[test_df.index].shift(-1)   # your actual next-period returns\n",
    "\n",
    "strat_ret, base_ret, metrics, w = bt.vol_managed_backtest(\n",
    "    returns=actual_returns,\n",
    "    pred_vol=oos_pred,\n",
    "    sigma_target=sigma_target\n",
    ")\n",
    "\n",
    "table = bt.metrics_to_table(metrics)\n",
    "display(table.round(4))\n",
    "bt.plot_backtest(strat_ret, base_ret, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d6b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_sharpe(returns, window=30 * 24 * 60):\n",
    "    roll_mean = returns.rolling(window).mean()\n",
    "    roll_std  = returns.rolling(window).std()\n",
    "    return roll_mean / roll_std\n",
    "\n",
    "# Rolling Sharpe\n",
    "roll_sharpe_strat = rolling_sharpe(strat_ret)\n",
    "roll_sharpe_base  = rolling_sharpe(base_ret)\n",
    "\n",
    "# Cumulative returns\n",
    "cum_strat = (1 + strat_ret).cumprod()\n",
    "cum_base  = (1 + base_ret).cumprod()\n",
    "\n",
    "# ---- Create the 3-panel plot ----\n",
    "fig, axs = plt.subplots(3, 1, figsize=(14, 12), sharex=True,\n",
    "                        gridspec_kw={'height_ratios': [2.2, 1.0, 1.3]})\n",
    "\n",
    "# Panel 1: Cumulative returns\n",
    "axs[0].plot(cum_strat, label=\"Strategy\", color=\"blue\")\n",
    "axs[0].plot(cum_base, label=\"Buy & Hold\", color=\"gray\", alpha=0.7)\n",
    "axs[0].set_title(\"Cumulative Returns\")\n",
    "axs[0].set_ylabel(\"Growth of $1\")\n",
    "axs[0].legend()\n",
    "axs[0].grid(alpha=0.3)\n",
    "\n",
    "# Panel 2: Position weights\n",
    "axs[1].plot(w, color=\"purple\")\n",
    "axs[1].set_title(\"Position Weight (Vol Targeting)\")\n",
    "axs[1].set_ylabel(\"Weight\")\n",
    "axs[1].grid(alpha=0.3)\n",
    "\n",
    "# Panel 3: Rolling Sharpe\n",
    "axs[2].plot(roll_sharpe_strat, label=\"Strategy Rolling Sharpe\", color=\"blue\")\n",
    "axs[2].plot(roll_sharpe_base,  label=\"Buy & Hold Rolling Sharpe\", color=\"gray\", alpha=0.7)\n",
    "axs[2].axhline(0, color=\"black\", lw=1)\n",
    "axs[2].set_title(\"Rolling 30-day Sharpe Ratio\")\n",
    "axs[2].set_ylabel(\"Sharpe\")\n",
    "axs[2].set_xlabel(\"Time\")\n",
    "axs[2].grid(alpha=0.3)\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
